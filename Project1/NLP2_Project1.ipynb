{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import needed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from ipywidgets import *\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from aer import *\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from enum import Enum\n",
    "from scipy.special import digamma\n",
    "from random import random\n",
    "\n",
    "import mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create supporting functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_and_update_files(file_f,file_e,null='<NULL>'):\n",
    "    \"\"\"\n",
    "    given a french and an english file, it will loop over the pairs \n",
    "    of lines. For every occuring combination in a line, a pair is \n",
    "    added to the dict. \n",
    "    \"\"\"\n",
    "    print(\"creating pairs\")\n",
    "    counter_e = Counter()\n",
    "    counter_f = Counter()\n",
    "    for line_num, (line_f, line_e) in tqdm(enumerate(zip(file_f,file_e)),total=len(file_f), desc='Count Words', leave=True):\n",
    "        words_f = line_f.split()\n",
    "        words_e = line_e.split()\n",
    "        file_f[line_num] = words_f\n",
    "        file_e[line_num] = words_e\n",
    "        \n",
    "        for word_f in words_f:\n",
    "            counter_f[word_f] += 1\n",
    "            for word_e in words_e:\n",
    "                counter_e[word_e] += 1\n",
    "                    \n",
    "    fe_pairs = dict()\n",
    "    vocab_e = set()\n",
    "    vocab_f = set()\n",
    "    fe_pairs[('<LOW>','<LOW>')] = 1\n",
    "    for line_num, (line_f, line_e) in tqdm(enumerate(zip(file_f,file_e)),total=len(file_f), desc='Pairs', leave=True):\n",
    "        c = 0\n",
    "        for i,f in enumerate(line_f):\n",
    "            if counter_f[f] == 1:\n",
    "                file_f[line_num][i] = '<LOW>'\n",
    "                f = '<LOW>'\n",
    "            fe_pairs[(f, null)] = 1\n",
    "            if f not in vocab_f:\n",
    "                vocab_f.update([f])\n",
    "            for j,e in enumerate(line_e):\n",
    "                if not c and e != '<LOW>' and e != null and counter_e[e] == 1:\n",
    "                    file_e[line_num][j] = '<LOW>'\n",
    "                    e = '<LOW>'\n",
    "                fe_pairs[(f,e)] = 1\n",
    "                if not c and e not in vocab_e:\n",
    "                    vocab_e.update([e])\n",
    "            c += 1\n",
    "\n",
    "    return fe_pairs, vocab_f, vocab_e\n",
    "\n",
    "def update_files(vocab_f,vocab_e,file_f,file_e,null='<NULL>'):\n",
    "    \"\"\"\n",
    "    given a french and an english file and the vocabularies, \n",
    "    it will update the files with non occuring \n",
    "    \"\"\"\n",
    "    for line_num, (line_f, line_e) in enumerate(zip(file_f,file_e)):\n",
    "        words_f = line_f.split()\n",
    "        words_e = line_e.split()\n",
    "        for i,f in enumerate(words_f):\n",
    "            if f not in vocab_f:\n",
    "                words_f[i] = '<LOW>'\n",
    "        for i,e in enumerate(words_e):\n",
    "            if e not in vocab_e:\n",
    "                words_e[i] = '<LOW>'\n",
    "        file_f[line_num] = words_f\n",
    "        file_e[line_num] = words_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different enum classes, that can are used to set certain hyperparameters for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBM_model(Enum):\n",
    "    I = 1\n",
    "    II = 2\n",
    "    \n",
    "class Initialization_type(Enum):\n",
    "    uniform = 1\n",
    "    random = 2\n",
    "    modelI = 3\n",
    "    \n",
    "class Termination_type(Enum):\n",
    "    epochs = 1\n",
    "    perplexity_convergence = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics calculation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexities(model,t,jump_dist,max_jump,file_f_train,file_e_train,file_f_val,file_e_val,calc_LL_train,null='<NULL>'):\n",
    "    \"\"\"\n",
    "    Given the model, it determines which perplexity calculation should be done. \n",
    "    It calculates the perplexity for both the training and the validation data. \n",
    "    \"\"\"\n",
    "    train_log_likelihood = -1 \n",
    "    train_perplexity = -1\n",
    "    if calc_LL_train:\n",
    "        train_log_likelihood, train_perplexity = calculate_perplexity(model,\n",
    "                                                                     t,\n",
    "                                                                     jump_dist,\n",
    "                                                                     max_jump,\n",
    "                                                                     file_f_train,\n",
    "                                                                     file_e_train,\n",
    "                                                                     null=null)        \n",
    "    val_log_likelihood, val_perplexity = calculate_perplexity(model,\n",
    "                                                             t,\n",
    "                                                             jump_dist,\n",
    "                                                             max_jump,\n",
    "                                                             file_f_val,\n",
    "                                                             file_e_val,\n",
    "                                                             null=null)\n",
    "    \n",
    "    return train_log_likelihood, val_log_likelihood, train_perplexity, val_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model,t,jump_dist, max_jump,file_f,file_e,null='<NULL>'):\n",
    "    if model == IBM_model.I:\n",
    "        log_likelihood,N = calculate_log_likelihood_modelI(t, file_f, file_e, null)\n",
    "    else:\n",
    "        log_likelihood,N = calculate_log_likelihood_modelII(t, file_f, file_e, jump_dist, max_jump, null)\n",
    "    \n",
    "    perplexity = np.exp(-1*log_likelihood/N)\n",
    "    return log_likelihood,perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics_tracker:\n",
    "    def __init__(self,\n",
    "                 save_prefix, \n",
    "                 align_path, \n",
    "                 validation_truth, \n",
    "                 validation_file_f, \n",
    "                 validation_file_e,\n",
    "                 train_file_f,\n",
    "                 train_file_e,\n",
    "                 test_truth,\n",
    "                 test_file_f,\n",
    "                 test_file_e,\n",
    "                 vocab_f,\n",
    "                 vocab_e,\n",
    "                 calc_LL_train,\n",
    "                 file_enc):\n",
    "                \n",
    "        self.save_prefix = save_prefix\n",
    "        self.align_path = align_path\n",
    "        self.validation_truth = validation_truth\n",
    "        self.validation_file_f = validation_file_f\n",
    "        self.validation_file_e = validation_file_e\n",
    "        self.train_file_f = train_file_f\n",
    "        self.train_file_e = train_file_e\n",
    "        self.test_truth = test_truth\n",
    "        self.test_file_f = test_file_f\n",
    "        self.test_file_e = test_file_e\n",
    "        self.vocab_f = vocab_f\n",
    "        self.vocab_e = vocab_e\n",
    "        self.calc_LL_train = calc_LL_train\n",
    "        self.file_enc = file_enc\n",
    "        \n",
    "        # Track\n",
    "        self.val_aers = []\n",
    "        self.train_log_likelihoods = []\n",
    "        self.val_log_likelihoods = []\n",
    "        self.train_perplexities = []\n",
    "        self.val_perplexities = []\n",
    "        self.test_aer = None\n",
    "    \n",
    "    def track_metrics(self, epoch, model, t, jump_dist=None, max_jump=None):\n",
    "        aer = self.calculate_aer_validation(epoch, model, t, jump_dist, max_jump)\n",
    "        train_ll, val_ll, train_pp, val_pp = self.calculate_perplexities(model, t, jump_dist, max_jump)\n",
    "        \n",
    "        # Store\n",
    "        self.val_aers.append(aer)\n",
    "        self.train_log_likelihoods.append(train_ll)\n",
    "        self.val_log_likelihoods.append(val_ll)\n",
    "        self.train_perplexities.append(train_pp)\n",
    "        self.val_perplexities.append(val_pp)\n",
    "        \n",
    "    def print_last_metrics(self, epoch = None, aer=True,train_ll=True,val_ll=True,train_pp=True,val_pp=True):\n",
    "        if epoch == None:\n",
    "            epoch = len(val_aers)\n",
    "        print('Results Epoch: '+str(epoch))\n",
    "        print('====================')\n",
    "        if aer and self.val_aers:\n",
    "            print('AER:\\n\\t validation:\\t{0}'.format(self.val_aers[-1]))\n",
    "        if train_ll or val_ll:\n",
    "            print('Log Likelihood:')\n",
    "            if train_ll and self.train_log_likelihoods:\n",
    "                print('\\t train:\\t\\t{0}'.format(self.train_log_likelihoods[-1]))\n",
    "            if val_ll and self.val_log_likelihoods:\n",
    "                print('\\t validation:\\t{0}'.format(self.val_log_likelihoods[-1]))\n",
    "        if train_pp or val_pp:\n",
    "            print('Perplexity:')\n",
    "            if train_pp and self.train_perplexities:\n",
    "                print('\\t train:\\t\\t{0}'.format(self.train_perplexities[-1]))\n",
    "            if val_ll and self.val_perplexities:\n",
    "                print('\\t validation:\\t{0}'.format(self.val_perplexities[-1]))\n",
    "    \n",
    "    def save_metrics(self, file_name = 'metrics.p'):\n",
    "        metrics = {'train_log_likelihoods': self.train_log_likelihoods,\n",
    "                   'val_log_likelihoods': self.val_log_likelihoods,\n",
    "                   'train_perplexities': self.train_perplexities,\n",
    "                   'val_perplexities': self.val_perplexities,\n",
    "                   'val_aers': self.val_aers,\n",
    "                   'test_aer': self.test_aer}\n",
    "        pickle.dump(metrics, open(file_name, \"wb\"))\n",
    "    \n",
    "    def calculate_aer_validation(self, epoch, model, t, jump_dist=None, max_jump=None):\n",
    "        return self.calculate_aer(epoch, model, t, self.validation_file_f, self.validation_file_e, self.validation_truth, jump_dist, max_jump)\n",
    "        \n",
    "    def calculate_aer_test(self, epoch, model, t, jump_dist=None, max_jump=None):\n",
    "        self.test_aer = self.calculate_aer(epoch, model, t, self.test_file_f, self.test_file_e, self.test_truth, jump_dist, max_jump)\n",
    "        return self.test_aer\n",
    "    \n",
    "    def calculate_aer(self, epoch, model, t, file_f, file_e, file_truth, jump_dist, max_jump):\n",
    "        align_file = os.path.join(self.align_path,'{0}validation_epoch{1}.align'.format(self.save_prefix, epoch))\n",
    "        if model == IBM_model.I:\n",
    "            create_alignments_modelI(t, file_f, file_e, align_file, self.file_enc)\n",
    "        elif model == IBM_model.II:\n",
    "            create_alignments_modelII(t, jump_dist, max_jump, file_f, file_e, align_file, self.file_enc)\n",
    "\n",
    "        aer = test(file_truth, align_file)\n",
    "        return aer\n",
    "    \n",
    "    def calculate_perplexities(self, model, t, jump_dist, max_jump):\n",
    "        train_ll, val_ll, train_pp, val_pp = calculate_perplexities(model,\n",
    "                                                                    t,\n",
    "                                                                    jump_dist,\n",
    "                                                                    max_jump,\n",
    "                                                                    self.train_file_f,\n",
    "                                                                    self.train_file_e,\n",
    "                                                                    self.validation_file_f,\n",
    "                                                                    self.validation_file_e,\n",
    "                                                                    self.calc_LL_train)\n",
    "\n",
    "        return train_ll, val_ll, train_pp, val_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM I\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params_modelI(initial_method, pairs, null='<NULL>'):\n",
    "    # Returns: t[(f,e)] - translation probabilities\n",
    "    \n",
    "    assert initial_method == Initialization_type.uniform, 'Unsupported initalization method {} for IBM model I'.format(initial_method)\n",
    "    \n",
    "    e_vocab_size = sum(1 for k,v in tqdm(pairs,  desc='Init Norm', leave=True) if v != null)\n",
    "    t = dict(zip(pairs,[1.0/e_vocab_size]*len(pairs)))    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "'''\n",
    "E-step:\n",
    "    for each word j in french sentence:\n",
    "        the probability of fj|ei divided by (for t=0>m: fj|et)\n",
    "        \n",
    "M-step:\n",
    "    E[fe]/E[e]\n",
    "'''\n",
    "def em_step_modelI(t, file_f, file_e, use_VB, alpha):\n",
    "    num_lines = len(file_f)\n",
    "    \n",
    "    # Set to zero\n",
    "    cooccurrences = defaultdict(float) # count words e and f happen together\n",
    "    total_f = defaultdict(float) # count word f happens\n",
    "    counter_f = Counter()\n",
    "    total_e = defaultdict(float) # count word e happens\n",
    "    \n",
    "    for f_sentence, e_sentence in tqdm(zip(file_f,file_e),total=num_lines,  desc='E-step', leave=True):\n",
    "        for e in e_sentence:\n",
    "            total_e[e] = 0\n",
    "            for f in f_sentence:\n",
    "                total_e[e] += t[(f,e)]\n",
    "                counter_f[f] += 1\n",
    "\n",
    "        for e in e_sentence:\n",
    "            for f in f_sentence:\n",
    "                temp = t[(f,e)] / total_e[e]\n",
    "                cooccurrences[(f,e)] += temp\n",
    "                total_f[f] += temp\n",
    "\n",
    "    for f,e in tqdm(cooccurrences.keys(),  desc='M-Step', leave=True):\n",
    "        if use_VB:\n",
    "            #theta_f|e =  exp( digamma(lambda_f|e) - digamma(sum_f' lambda(f'|e))) where lambda_f|e = E(#f-e)+alpha_f   \n",
    "            t[(f,e)] = np.exp( digamma(cooccurrences[(f,e)] + alpha) - digamma(total_f[f] + counter_f[f]*alpha))\n",
    "        else:\n",
    "            t[(f,e)] = cooccurrences[(f,e)] / total_f[f]\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alignments_modelI(t, file_f, file_e, target, file_enc='utf-8'):\n",
    "    # open file to write to\n",
    "    with open(target,'w',encoding=file_enc) as tar:\n",
    "        # for each sentence in list\n",
    "        for line_num, (f_sentence,e_sentence) in tqdm(enumerate(zip(file_f,file_e)),total=len(file_f),  desc='AlignI', leave=True):\n",
    "            # for each word in sentence, find the best alignment\n",
    "            for ind_f,f in enumerate(f_sentence):\n",
    "                ind_f += 1 #0 is reserved for null\n",
    "                max_ind_e = 0 #when no alignment is found, align to zero\n",
    "                max_p = 0\n",
    "                for ind_e,e in enumerate(e_sentence):\n",
    "                    ind_e += 1 #0 is reserved for null\n",
    "                    if (f,e) in t:\n",
    "                        if t[(f,e)] > max_p:\n",
    "                            max_p = t[(f,e)]\n",
    "                            max_ind_e = ind_e\n",
    "\n",
    "                if max_ind_e != 0: # Skip null alignments\n",
    "                    # write to file. Output: sentence_line english_pos french_pos probability\n",
    "                    tar.write('%d %d %d P %f\\n'%(line_num, max_ind_e, ind_f, max_p)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_modelI(t, file_f, file_e, null='<NULL>'):\n",
    "    log_likelihood = 0\n",
    "    N = 0\n",
    "    for sentence_f, sentence_e in tqdm(zip(file_f,file_e),total=len(file_f), desc='Calc LL', leave=True):\n",
    "        l = len(sentence_e)\n",
    "        m = len(sentence_f)\n",
    "        sentence_e = [null] + sentence_e\n",
    "        \n",
    "        alignment_prob = -np.log(m*np.log(l+1))\n",
    "\n",
    "        for f in sentence_f:\n",
    "            max_p = 0\n",
    "            for e in sentence_e:\n",
    "                if (f,e) in t and t[(f,e)] > max_p:\n",
    "                    max_p = t[(f,e)]        \n",
    "            N += 1\n",
    "            log_likelihood += alignment_prob + np.log(max_p)\n",
    "    return log_likelihood, N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM II\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params_modelII(initial_method, pairs, max_jump, t=None, null='<NULL>'):\n",
    "    # Returns: t[(f,e)] and jump_dist\n",
    "    \n",
    "    if t == None:\n",
    "        if initial_method == Initialization_type.uniform:\n",
    "            t = init_params_modelI(initial_method, pairs)\n",
    "        elif initial_method == Initialization_type.random:\n",
    "            t = dict(zip(pairs,[random() for x in range(len(pairs))]))\n",
    "        elif initial_method == Initialization_type.modelI:\n",
    "            # Initialize t from model I output 10 iterations\n",
    "            t = em_algorithm(model=IBM_model.I,max_epoch=10,initial_method=Initialization_type.uniform,save_pickles=False)\n",
    "\n",
    "    # Initialize jump distribution\n",
    "    jump_dist = 1. / (2 * max_jump) * np.ones([1, 2 * max_jump])\n",
    "    \n",
    "    return t, jump_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "def em_step_modelII(t, jump_dist, max_jump, file_f, file_e, null='<NULL>'):\n",
    "    # Set to zero\n",
    "    counts_e_f = defaultdict(float) # counts words e and f happen together\n",
    "    counts_e = defaultdict(float) # counts word e happens\n",
    "    counts_jump = [0] * max_jump*2 # counts per jump between words\n",
    "    \n",
    "    num_lines = len(file_f)\n",
    "    \n",
    "    for f_sentence, e_sentence in tqdm(zip(file_f,file_e),total=num_lines,  desc='E-step', leave=True):\n",
    "        # Get lengths\n",
    "        l = len(e_sentence)\n",
    "        m = len(f_sentence)\n",
    "        f_sentence = [None] + f_sentence\n",
    "        e_sentence = [null] + e_sentence\n",
    "      \n",
    "        for i in range(1, m+1): # french\n",
    "            f = f_sentence[i]\n",
    "            den = sum(jump_dist[0, jump_func(x,i,l,m,max_jump)]*t[(f,e_sentence[x])] for x in range(0, l+1))\n",
    "            assert den != 0, 'normalization denominator is zero. i: {}, l:{}, m:{}'.format(i,l,m)\n",
    "            \n",
    "            for j in range(0, l+1): # english\n",
    "                e = e_sentence[j]\n",
    "                \n",
    "                jump_idx = jump_func(j, i, l, m, max_jump)\n",
    "                delta = t[(f,e)] * jump_dist[0, jump_idx] / den\n",
    "\n",
    "                counts_e_f[(e,f)] += delta\n",
    "                counts_e[e] += delta\n",
    "                counts_jump[jump_idx] += delta\n",
    "\n",
    "    for e,f in tqdm(counts_e_f.keys(),  desc='M-step', leave=True):\n",
    "        assert counts_e[e] != 0, 'counts_e[{}] is zero'.format(e)\n",
    "        t[(f,e)] = counts_e_f[(e,f)] / counts_e[e]\n",
    "\n",
    "    jump_den = sum(counts_jump)\n",
    "    assert jump_den != 0, 'normalization denominator for jumps is zero'\n",
    "    for i,c in enumerate(counts_jump):\n",
    "        jump_dist[0,i] = c / jump_den        \n",
    "\n",
    "    return t, jump_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jump function. From https://uva-slpl.github.io/nlp2/projects/2018/04/12/project1.html\n",
    "\n",
    "def jump_func(i, j, m, n, max_jump):\n",
    "    \"\"\"\n",
    "    Alignment of french word j to english word i. \n",
    "    i = 0, to ,m  (we use m as in Wilker's lecture slides -- length of English sentence)\n",
    "    j = 1, to ,n  (we use n as in Wilker's lecture slides -- length of French sentence)\n",
    "    That is: a_j = i\n",
    "    with e.g. max_jump = 100\n",
    "    from[-max_jump, max_jump] to [0, 2*max_jump + 1] \n",
    "    \"\"\"\n",
    "    # We normalise j by the lenght of the French sentence and scale the result to the length of the English sentence\n",
    "    # this gives us a continuous value that is an interpolation of where we j would be in the English sentence\n",
    "    # if alignments were a linear function of the length ratio\n",
    "    jump = np.floor(i - (j * m / n)) \n",
    "    # then we collapse all jumps that are too far to the right to the maximum jump value allowed\n",
    "    if jump > max_jump:  # or we collapse all jumps that are too far to the left to the maximum (negative) jump allowed\n",
    "        jump = max_jump   \n",
    "    elif jump < -max_jump:\n",
    "        jump = -max_jump\n",
    "    # Now we shift the jump values so they start from 0\n",
    "    #  this is only necessary if you use python lists or numpy vectors to store jump probabilities\n",
    "    #  otherwise, you can use a python dict and this shifting is not required since dicts can have negative keys\n",
    "    idx = (int)(jump + max_jump)\n",
    "    if idx >= 2*max_jump: # Fix for out of bounds index\n",
    "        idx -= 1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alignments_modelII(t, jump_dist, max_jump, file_f, file_e, target, file_enc='utf-8', null='<NULL>'):\n",
    "    # open file to write to\n",
    "    with open(target,'w',encoding=file_enc) as tar:\n",
    "        # for each sentence in list\n",
    "        for line_num, (f_sentence,e_sentence) in tqdm(enumerate(zip(file_f,file_e)), total=len(file_f), desc='AlignII', leave=True):\n",
    "            # Get lengths\n",
    "            l = len(e_sentence)\n",
    "            m = len(f_sentence)\n",
    "            f_sentence = [None] + f_sentence\n",
    "            e_sentence = [null] + e_sentence\n",
    "\n",
    "            # for each word position in sentence, find the best alignment\n",
    "            for i in range(1, m+1): # french\n",
    "                max_p = 0\n",
    "                max_ind = 0 #when no alignment is found, align to zero\n",
    "                f = f_sentence[i]\n",
    "                for j in range(0, l+1): # english\n",
    "                    e = e_sentence[j]\n",
    "\n",
    "                    if (f,e) in t:\n",
    "                        p = t[(f,e)]*jump_dist[0, jump_func(j,i,l,m,max_jump)]\n",
    "\n",
    "                        if p >= max_p:\n",
    "                            max_p = p\n",
    "                            max_ind = j\n",
    "\n",
    "                if max_ind != 0: # Skip null alignments\n",
    "                    # write to file. Output: sentence_line english_pos french_pos probability\n",
    "                    tar.write('%d %d %d P %f\\n'%(line_num, max_ind, i, max_p)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_modelII(t, file_f, file_e, jump_dist, max_jump, null='<NULL>'):\n",
    "    log_likelihood = 0\n",
    "    N = 0\n",
    "    for sentence_f, sentence_e in tqdm(zip(file_f,file_e),total=len(file_f),  desc='Calc LL', leave=True):\n",
    "        l = len(sentence_e)\n",
    "        m = len(sentence_f)\n",
    "\n",
    "        sentence_e = [null] + sentence_e\n",
    "        sentence_f = [None] + sentence_f\n",
    "        \n",
    "        for i in range(1, m+1): # french\n",
    "            f = sentence_f[i]\n",
    "            max_p = 0\n",
    "            max_align_p = 0\n",
    "            for j in range(0, l+1): # english\n",
    "                e = sentence_e[j]\n",
    "                if (f,e) in t and t[(f,e)] >= max_p:\n",
    "                    max_p = t[(f,e)]\n",
    "                    max_align_p = jump_dist[0, jump_func(j,i,l,m,max_jump)]                \n",
    "            N += 1\n",
    "            log_likelihood += np.log(max_align_p) + np.log(max_p)\n",
    "    return log_likelihood, N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_algorithm(model,\n",
    "                 t=None, #Only used for model II\n",
    "                 max_epoch=10, \n",
    "                 threshold=0.01,\n",
    "                 initial_method=Initialization_type.uniform, #How to initialize t\n",
    "                 terminate_method=Termination_type.epochs, \n",
    "                 train_file_f='data/training/hansards.36.2.f',\n",
    "                 train_file_e='data/training/hansards.36.2.e',\n",
    "                 validation_file_f='data/validation/dev.f',\n",
    "                 validation_file_e='data/validation/dev.e',\n",
    "                 validation_truth='data/validation/dev.wa.nonullalign',\n",
    "                 test_file_f = 'data/testing/test/test.f',\n",
    "                 test_file_e = 'data/testing/test/test.e',\n",
    "                 test_truth = 'data/testing/answers/test.wa.nonullalign',\n",
    "                 pickles_path='data/pickles/',\n",
    "                 align_path='data/alignments/',\n",
    "                 save_prefix='',\n",
    "                 save_pickles=True,\n",
    "                 use_VB=False,\n",
    "                 calc_LL_train=True,\n",
    "                 alpha=0.1, #Only used if VB is used\n",
    "                 file_enc='utf-8'):\n",
    "    \n",
    "    # test if prefix exists and correct format\n",
    "    if save_prefix != '' and save_prefix[-1]!='_':\n",
    "        save_prefix+='_'\n",
    "    \n",
    "    # read in all the files\n",
    "    with open(train_file_f, encoding=file_enc) as f:\n",
    "        train_file_f = f.readlines()\n",
    "    with open(train_file_e, encoding=file_enc) as f:\n",
    "        train_file_e = f.readlines()\n",
    "    with open(validation_file_f, encoding=file_enc) as f:\n",
    "        validation_file_f = f.readlines()\n",
    "    with open(validation_file_e, encoding=file_enc) as f:\n",
    "        validation_file_e = f.readlines()\n",
    "    with open(test_file_f, encoding=file_enc) as f:\n",
    "        test_file_f = f.readlines()\n",
    "    with open(test_file_e, encoding=file_enc) as f:\n",
    "        test_file_e = f.readlines()\n",
    "    \n",
    "    # get word pairs from corpus\n",
    "    pairs, vocab_f, vocab_e = create_pairs_and_update_files(train_file_f, train_file_e)\n",
    "    update_files(vocab_f, vocab_e, validation_file_f, validation_file_e)\n",
    "    update_files(vocab_f, vocab_e, test_file_f, test_file_e)\n",
    "\n",
    "    #initialize parameters\n",
    "    if model == IBM_model.I:\n",
    "        t = init_params_modelI(initial_method, pairs)\n",
    "    elif model == IBM_model.II:\n",
    "        # For jump function\n",
    "        max_jump = 100        \n",
    "        t, jump_dist = init_params_modelII(initial_method, pairs, max_jump, t)\n",
    "    \n",
    "    tracker = Metrics_tracker(save_prefix, \n",
    "                              align_path, \n",
    "                              validation_truth, \n",
    "                              validation_file_f, \n",
    "                              validation_file_e,\n",
    "                              train_file_f,\n",
    "                              train_file_e,\n",
    "                              test_truth,\n",
    "                              test_file_f,\n",
    "                              test_file_e,\n",
    "                              vocab_f,\n",
    "                              vocab_e,\n",
    "                              calc_LL_train,\n",
    "                              file_enc)\n",
    "    \n",
    "    # calculate initial scores before training\n",
    "    tracker.track_metrics(0, model, t, jump_dist if model == IBM_model.II else None, \n",
    "                                       max_jump if model == IBM_model.II else None)\n",
    "    \n",
    "    \n",
    "    #print train result\n",
    "    tracker.print_last_metrics('Init')\n",
    "        \n",
    "    # loop for max_epochs or till convergence is reached\n",
    "    for epoch in range(1,max_epoch+1):\n",
    "        print(\"start epoch: \"+str(epoch))\n",
    "        \n",
    "        # do an EM step\n",
    "        if model == IBM_model.I:\n",
    "            t = em_step_modelI(t, train_file_f, train_file_e, use_VB, alpha)\n",
    "        else:\n",
    "            t, jump_dist = em_step_modelII(t, jump_dist, max_jump, train_file_f, train_file_e)\n",
    "        \n",
    "        # create AER results and calculate the loglikelihoods/perplexity\n",
    "        tracker.track_metrics(epoch, model, t, jump_dist if model == IBM_model.II else None, \n",
    "                                               max_jump if model == IBM_model.II else None)\n",
    "        tracker.print_last_metrics(epoch)\n",
    "        \n",
    "        #store train progress\n",
    "        if save_pickles:\n",
    "            pickle.dump(t, open( os.path.join(pickles_path,'{0}t_epoch{1}.p'.format(save_prefix,epoch)), \"wb\" ))\n",
    "            if model == IBM_model.II:\n",
    "                pickle.dump(jump_dist, open( os.path.join(pickles_path,'{0}jump_dist_epoch{1}.p'.format(save_prefix,epoch)), \"wb\" ))\n",
    "        \n",
    "        #test for convergence\n",
    "        if terminate_method == Termination_type.perplexity_convergence:\n",
    "            if (len(tracker.train_perplexities) > 2) and (abs(tracker.train_perplexities[-2]-train_perplexity) < threshold):\n",
    "                print('Reached Convergence!')\n",
    "                break\n",
    "    \n",
    "    # Dump metrics to pickles\n",
    "    test_aer = tracker.calculate_aer_test(epoch+1,\n",
    "                                   model,\n",
    "                                   t,\n",
    "                                   jump_dist if model == IBM_model.II else None,\n",
    "                                   max_jump if model == IBM_model.II else None)\n",
    "    print('=================\\nTEST AER RESULT: {0}\\n================='.format(test_aer))\n",
    "    tracker.save_metrics(os.path.join(pickles_path,'{}metrics.p'.format(save_prefix)))\n",
    "    \n",
    "    if model == IBM_model.I:\n",
    "        return t\n",
    "    elif model == IBM_model.II:\n",
    "        return t, jump_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RUNNING THE SCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count Words:   0%|          | 195/231164 [00:00<01:58, 1949.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count Words: 100%|██████████| 231164/231164 [01:56<00:00, 1976.63it/s]\n",
      "Pairs: 100%|██████████| 231164/231164 [01:36<00:00, 2386.56it/s]\n",
      "Init Norm: 100%|██████████| 11614796/11614796 [00:14<00:00, 810577.80it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1739.05it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:56<00:00, 1307.98it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1675.46it/s]\n",
      "E-step:   0%|          | 141/231164 [00:00<05:29, 700.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: Init\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.9065155807365439\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2684.922037257008\n",
      "\t validation:\t-1613.9292653144628\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005829946141471\n",
      "\t validation:\t9.378871556029178\n",
      "start epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:30<00:00, 513.39it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:32<00:00, 354430.33it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1683.11it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:43<00:00, 1411.99it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1610.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 1\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.8016997167138811\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2415.721303235616\n",
      "\t validation:\t-1352.3986734140342\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005245259776225\n",
      "\t validation:\t6.525557012167654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 86/231164 [00:00<04:31, 851.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:50<00:00, 491.22it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:29<00:00, 396321.61it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1731.69it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [20:05<00:00, 191.77it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1675.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 2\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.49008498583569404\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2401.468665188581\n",
      "\t validation:\t-1339.9927730119987\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005214304932093\n",
      "\t validation:\t6.414235365164364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 133/231164 [00:00<05:53, 654.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:37<00:00, 504.86it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:31<00:00, 368805.96it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1600.53it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:40<00:00, 1443.76it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1826.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 3\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.4230406043437205\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2395.263123189799\n",
      "\t validation:\t-1334.9009834654034\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005200827345826\n",
      "\t validation:\t6.36909683068159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 81/231164 [00:00<04:48, 801.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:26<00:00, 518.16it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:28<00:00, 413393.11it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1729.63it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:36<00:00, 1477.73it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1746.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 4\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.39565627950897075\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2392.868572885601\n",
      "\t validation:\t-1333.2165482318226\n",
      "Perplexity:\n",
      "\t train:\t\t1.000519562671578\n",
      "\t validation:\t6.354234405110042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 86/231164 [00:00<04:29, 858.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:28<00:00, 514.85it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:29<00:00, 391693.81it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1627.95it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:36<00:00, 1475.12it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1743.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 5\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.38243626062322944\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2391.7396050427124\n",
      "\t validation:\t-1332.6361177644642\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005193174755664\n",
      "\t validation:\t6.349121080447569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 85/231164 [00:00<04:33, 843.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:26<00:00, 517.77it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:35<00:00, 325941.80it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1651.78it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:36<00:00, 1477.36it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1748.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 6\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.3729933899905571\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2391.112790368089\n",
      "\t validation:\t-1332.4648036622189\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005191813402197\n",
      "\t validation:\t6.347612668843216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 87/231164 [00:00<04:29, 858.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:26<00:00, 517.33it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:28<00:00, 409809.38it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1721.84it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:36<00:00, 1473.90it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1668.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 7\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.3682719546742209\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2390.795344446599\n",
      "\t validation:\t-1332.551271484064\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005191123954296\n",
      "\t validation:\t6.348373968641693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 83/231164 [00:00<04:40, 822.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:31<00:00, 512.38it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:30<00:00, 374216.98it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1494.00it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:36<00:00, 1475.45it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1046.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 8\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.36449480642115206\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2390.6379785837767\n",
      "\t validation:\t-1332.7894490089827\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005190782177789\n",
      "\t validation:\t6.350471457924301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 83/231164 [00:00<04:41, 819.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:34<00:00, 508.79it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:29<00:00, 390204.71it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1418.61it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:43<00:00, 1414.82it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1581.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 9\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.3616619452313503\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2390.5883109717\n",
      "\t validation:\t-1333.0700752772539\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005190674306728\n",
      "\t validation:\t6.35294365760056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step:   0%|          | 88/231164 [00:00<04:30, 854.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-step: 100%|██████████| 231164/231164 [07:35<00:00, 507.32it/s]\n",
      "M-Step: 100%|██████████| 11583295/11583295 [00:32<00:00, 360098.15it/s]\n",
      "AlignI: 100%|██████████| 37/37 [00:00<00:00, 1731.21it/s]\n",
      "Calc LL: 100%|██████████| 231164/231164 [02:34<00:00, 1499.75it/s]\n",
      "Calc LL: 100%|██████████| 37/37 [00:00<00:00, 1781.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Epoch: 10\n",
      "====================\n",
      "AER:\n",
      "\t validation:\t0.3616619452313503\n",
      "Log Likelihood:\n",
      "\t train:\t\t-2390.6066612801187\n",
      "\t validation:\t-1333.335899558221\n",
      "Perplexity:\n",
      "\t train:\t\t1.0005190714161012\n",
      "\t validation:\t6.355286345578848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AlignI: 100%|██████████| 447/447 [00:00<00:00, 2464.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "TEST AER RESULT: 0.352063734214764\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "# Run model I\n",
    "t = em_algorithm(model=IBM_model.I, max_epoch=10, save_prefix='modelI_report')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"}},"nbformat_minor":2,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project 2","metadata":{}},{"cell_type":"markdown","source":"##### import needed packages","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm_notebook, tqdm, tnrange\nfrom collections import defaultdict,Counter\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom random import shuffle\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nnp.set_printoptions(threshold=np.nan)","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Global for enabling GPU","metadata":{}},{"cell_type":"code","source":"run_gpu = torch.cuda.is_available()\n# run_gpu = False\nrun_gpu","metadata":{"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Classes and Functions","metadata":{}},{"cell_type":"markdown","source":"## Data Manipulation","metadata":{}},{"cell_type":"markdown","source":"### Cleaning and preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess(train_data, val_data, test_data, vocab_size=10000):\n    \n    # loop over all the given files\n    for data in [train_data, val_data, test_data]:\n        # contains a source and a target file\n        for k,v in data.items():\n            tokenized_path = v[:v.find('.')] + '_tokenized.{}'.format(k)\n\n            # Tokenize \n            tokenize_command = 'perl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l {lang} < {file_path} > {output_path}'.format(\n                lang=k, file_path=v, output_path=tokenized_path)\n            print('tokenize command:\\t{}'.format(tokenize_command))\n            \n            # Lowercase\n            lowercase_path = tokenized_path[:tokenized_path.find('.')] + '_lowercased.{}'.format(k)\n            lowercase_command = 'perl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < {file_path} > {output_path}'.format(\n                file_path=tokenized_path, output_path=lowercase_path)\n            print('lowercase command:\\t{}\\n'.format(lowercase_command))\n            \n    # BPE\n    # Get vocabulary using train data\n    script_name = 'python tools/subword-nmt/subword_nmt/learn_joint_bpe_and_vocab.py'\n    args = ' --input {train_en} {train_fr} -s {num_symbols} -o {codes_file} --write-vocabulary {vocab_file}.en {vocab_file}.fr'\n    substr_index = train_data['en'].find('/')\n    vocab_file_name = train_data['en'][:substr_index] + '/vocab'\n    codes_file_name = train_data['en'][:substr_index] + '/codes.bpe'\n    learn_vocab_command = script_name + args.format(\n        train_en='data/train/train_tokenized_lowercased.en',\n        train_fr='data/train/train_tokenized_lowercased.fr',\n        num_symbols=str(vocab_size),\n        codes_file=codes_file_name,\n        vocab_file=vocab_file_name\n    )\n    print('learn vocab command:\\t{}'.format(learn_vocab_command))\n    \n    # Process all files the same way for consistency\n    script_name = 'python tools/subword-nmt/subword_nmt/apply_bpe.py'\n    for data in [train_data, val_data, test_data]:\n        for k,v in data.items():\n            args = ' -c {codes_file} --vocabulary {vocab_file}.{lang} --vocabulary-threshold 50 < {train_file}.{lang} > {train_file}_bpe.{lang}'\n            train_file_name = v[:v.find('.')] + '_tokenized_lowercased'\n            bpe_command = script_name + args.format(\n                codes_file=codes_file_name,\n                vocab_file=vocab_file_name,\n                lang=k,\n                train_file=train_file_name\n            )\n            print('bpe command:\\t{}'.format(bpe_command))","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Building dictionaries and vocabularies","metadata":{}},{"cell_type":"code","source":"PAD = '<PAD>'\nUNK = '<UNK>'\nSTART = '<SOS>'\nEND = '<EOS>'","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DataProcessor():\n    def __init__(self, file_name, vocab_size):\n        self.max_sentence_length = -1\n        self.vocab_size = vocab_size\n        \n        self.file_name = file_name\n        self.sentences = self.load_data()\n        self.vocab,self.vocab_size = self.build_vocab()\n        self.w2i, self.i2w = self.build_dicts()        \n        \n    def load_data(self):\n        sentences = []\n        with open(self.file_name, 'r') as f:\n            for line in f:\n                sentences.append(line.split())                \n        return sentences\n    \n    def build_dicts(self):\n        \"\"\"\n        creates lookup tables to find the index given the word \n        and the otherway around \n        \"\"\"\n        w2i = defaultdict(lambda: w2i[UNK])\n        i2w = dict()\n        for i,w in enumerate(self.vocab):\n            i2w[i] = w\n            w2i[w] = i\n        return w2i, i2w    \n    \n    def build_vocab(self): \n        \"\"\"\n        builds a vocabulary with the most occuring words, in addition to\n        the UNK token at index 1 and PAD token at index 0. \n        START and END tokens are added to the vocabulary through the\n        preprocessed sentences.\n        with vocab size none, all existing words in the data are used\n        \"\"\"\n        vocab = Counter()\n        for s in self.sentences:\n            l = len(s)\n            if l > self.max_sentence_length:\n                self.max_sentence_length = l\n            for w in s:\n                vocab[w] += 1\n\n        vocab = [k for k,_ in vocab.most_common(self.vocab_size)]\n        vocab = [PAD,UNK,START,END] + vocab\n        return vocab,len(vocab)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Getting data batches","metadata":{}},{"cell_type":"code","source":"def batch_generator(source_processor, target_processor, batch_size):\n    idx = np.arange(len(source_processor.sentences))\n    \n    if batch_size == 1:\n        bi = 0\n        while True:\n            b_words_source = np.zeros([batch_size, source_processor.max_sentence_length+1])\n            b_positions_source = np.zeros([batch_size, source_processor.max_sentence_length+1])\n            b_words_target = np.zeros([batch_size, target_processor.max_sentence_length+2])\n            \n            sent_source = source_processor.sentences[bi] + [END]\n            sent_target = [START] + target_processor.sentences[bi] + [END]\n                \n            b_words_source[0, :len(sent_source)] = np.array([source_processor.w2i[w] for w in sent_source])\n            b_positions_source[0, :len(sent_source)] = np.array([i for i in range(len(sent_source))])\n            b_words_target[0, :len(sent_target)] = np.array([target_processor.w2i[w] for w in sent_target])\n            \n            if run_gpu:\n                word_tens = torch.from_numpy(b_words_source).type(torch.cuda.LongTensor)\n                pos_tens = torch.from_numpy(b_positions_source).type(torch.cuda.LongTensor)\n                tar_tens = torch.from_numpy(b_words_target).type(torch.cuda.LongTensor)\n                sentence_lengths_source = torch.cuda.FloatTensor([len(sent_source)])\n                sentence_lengths_target = torch.cuda.FloatTensor([len(sent_target)])\n            else:\n                word_tens = torch.from_numpy(b_words_source).type(torch.LongTensor)\n                pos_tens = torch.from_numpy(b_positions_source).type(torch.LongTensor)\n                tar_tens = torch.from_numpy(b_words_target).type(torch.LongTensor)\n                sentence_lengths_source = torch.FloatTensor([len(sent_source)])\n                sentence_lengths_target = torch.FloatTensor([len(sent_target)])\n                \n            bi += 1\n            if bi == len(source_processor.sentences):\n                bi = 0\n            yield (word_tens,\n                   pos_tens,\n                   tar_tens,\n                   sentence_lengths_source,\n                   sentence_lengths_target,\n                   np.ones(sentence_lengths_source[0]),\n                   np.ones(sentence_lengths_target[0]))\n    \n    else:\n        while True:\n            shuffle(idx)\n            batch_idx = [idx[i:i + batch_size] for i in range(0, len(idx) - (len(idx)%batch_size), batch_size)]\n            \n            for b_idx in batch_idx:\n                b_words_source = np.zeros([batch_size, source_processor.max_sentence_length+1])\n                b_positions_source = np.zeros([batch_size, source_processor.max_sentence_length+1])\n                b_words_target = np.zeros([batch_size, target_processor.max_sentence_length+2])\n\n                sentence_lengths_source = []\n                sentence_lengths_target = []\n                for i, bi in enumerate(b_idx):\n                    sent_source = source_processor.sentences[bi] + [END]\n                    sent_target = [START] + target_processor.sentences[bi] + [END]\n\n                    b_words_source[i, :len(sent_source)] = np.array([source_processor.w2i[w] for w in sent_source])\n                    b_positions_source[i, :len(sent_source)] = np.array([i for i in range(len(sent_source))])\n                    b_words_target[i, :len(sent_target)] = np.array([target_processor.w2i[w] for w in sent_target])\n\n                    sentence_lengths_source.append(len(sent_source))\n                    sentence_lengths_target.append(len(sent_target))\n                    \n                max_len_source = np.max(sentence_lengths_source)\n                max_len_target = np.max(sentence_lengths_target)\n                if run_gpu:\n                    word_tens = torch.from_numpy(b_words_source).type(torch.cuda.LongTensor)\n                    pos_tens = torch.from_numpy(b_positions_source).type(torch.cuda.LongTensor)\n                    tar_tens = torch.from_numpy(b_words_target).type(torch.cuda.LongTensor)\n                    sentence_lengths_source = torch.cuda.FloatTensor(sentence_lengths_source)\n                    sentence_lengths_target = torch.cuda.FloatTensor(sentence_lengths_target)\n                    source_mask = torch.from_numpy((b_words_source > 0).astype(int)).type(torch.cuda.FloatTensor)\n                    target_mask = torch.from_numpy((b_words_target > 0).astype(int)).type(torch.cuda.LongTensor)\n                else:\n                    word_tens = torch.from_numpy(b_words_source).type(torch.LongTensor)\n                    pos_tens = torch.from_numpy(b_positions_source).type(torch.LongTensor)\n                    tar_tens = torch.from_numpy(b_words_target).type(torch.LongTensor)\n                    sentence_lengths_source = torch.FloatTensor(sentence_lengths_source)\n                    sentence_lengths_target = torch.FloatTensor(sentence_lengths_target)\n                    source_mask = torch.from_numpy((b_words_source > 0).astype(int)).type(torch.FloatTensor)\n                    target_mask = torch.from_numpy((b_words_target > 0).astype(int)).type(torch.LongTensor)\n\n                yield (word_tens,\n                       pos_tens,\n                       tar_tens,\n                       sentence_lengths_source,\n                       sentence_lengths_target,\n                       source_mask,\n                       target_mask)","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Sequence 2 Sequence RNN's","metadata":{}},{"cell_type":"markdown","source":"### Encoder","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, source_vocab_size, source_max_length, embeddings_dim):\n        super().__init__()        \n        self.word_embeddings = nn.Embedding(source_vocab_size, embeddings_dim)\n        self.pos_embeddings = nn.Embedding(source_max_length, embeddings_dim)\n        \n    def forward(self, words_batch, pos_batch, sentence_lengths, mask): # all inputs are tensors\n        words_emb = self.word_embeddings(words_batch)\n        pos_emb = self.pos_embeddings(pos_batch)\n        full_emb = torch.add(words_emb,pos_emb)\n        mean_emb = full_emb.mul(mask.unsqueeze(2).expand_as(full_emb)).sum(dim=1).float()\n        mean_emb = mean_emb.div(sentence_lengths.float().view(-1,1)) # batched version of torch.mean(full_emb,1)\n        return full_emb, mean_emb","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, target_vocab_size, embeddings_dim, dropout_p=0.1):\n        super().__init__()\n        \n        self.embedding_dim = embedding_dims\n        self.dropout_p = dropout_p\n        \n        self.target_embeddings = nn.Embedding(target_vocab_size, embeddings_dim)\n        self.gru = nn.GRU(embeddings_dim*2, embeddings_dim, batch_first=True) # gru is an LSTM, and has 2 outputs\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.out = nn.Linear(embeddings_dim, target_vocab_size)\n        \n    def forward(self, gold_words_batch, hidden_batch, stacked_encoded_words_batch):\n        batch_size = gold_words_batch.size(0)\n        encoded_length = stacked_encoded_words_batch.size(1)\n        \n        emb = self.target_embeddings(gold_words_batch)\n        emb = self.dropout(emb)\n        \n        # attention            \n        alphas = torch.zeros(batch_size, encoded_length)\n        alphas = hidden_batch.view(batch_size,1,self.embedding_dim).bmm(\n            stacked_encoded_words_batch.view(batch_size,self.embedding_dim,encoded_length)) # batched version of dot product\n        \n        # Turn to probability distribution\n        alphas = F.softmax(alphas, dim=2)\n            \n        # context is weights x hidden states from encoder\n        context = torch.bmm(alphas, stacked_encoded_words_batch)\n        \n        # we have to concat context + emb        \n        input = torch.cat((emb, context), 2)\n        del(context)\n        \n        gru_output, hidden = self.gru(input, hidden_batch.view(1, batch_size, self.embedding_dim))\n        \n        output = self.out(gru_output)\n#         output = F.log_softmax(output, dim=2)        \n        \n        return output, hidden, alphas","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Encoder Decoder","metadata":{}},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    def __init__(self, \n                 embeddings_dim,\n                 source_vocab_size, \n                 source_max_length, \n                 target_vocab_size, \n                 dropout_p=0.1):\n        \n        super().__init__()\n        \n        self.source_vocab_size = source_vocab_size\n        self.target_vocab_size = target_vocab_size\n        \n        self.encoder = Encoder(source_vocab_size,\n                               source_max_length + 1, \n                               embeddings_dim)\n        self.decoder = Decoder(target_vocab_size, \n                               embeddings_dim,\n                               dropout_p=dropout_p)\n#         self.loss = nn.NLLLoss(ignore_index=0)\n        self.loss = nn.CrossEntropyLoss(ignore_index=0, reduce=False) # weight would be all ones except one, which is identical to ignore_index\n\n        if run_gpu:\n            self.encoder = self.encoder.cuda()\n            self.decoder = self.decoder.cuda()\n            self.loss = self.loss.cuda()\n\n    def forward(self, \n                words_batch_source,\n                pos_batch_source,\n                sentence_length_source,\n                words_batch_target,\n                sentence_lengths_target,\n                source_mask,\n                target_mask):        \n        # Encode\n        all_embs, hidden_state_batch = self.encoder(words_batch_source, \n                                                    pos_batch_source, \n                                                    sentence_length_source, \n                                                    source_mask)\n        \n#         #clean up\n#         del(words_batch_source)\n#         del(pos_batch_source)\n#         del(sentence_length_source)\n        \n        # Decode\n        batch_size,max_sent_len = words_batch_target.shape\n        out = torch.zeros((batch_size))\n        if run_gpu:\n            out = out.cuda()\n        for w_idx in range(max_sent_len-1):\n            prediction, hidden_state_batch, _ = self.decoder(words_batch_target[:,w_idx].view(-1,1), \n                                                          hidden_state_batch,\n                                                          all_embs)\n            out += self.loss(prediction.squeeze(1), words_batch_target[:,w_idx+1])        \n        #cleanup\n        del(all_embs)\n        del(prediction)\n        del(hidden_state_batch)\n#         del(words_batch_target)\n        out = torch.mean(torch.div(out,sentence_lengths_target))  # the loss is the average of losses, so divide over number of words in each sentence\n#         del(sentence_lengths_target)\n        return out","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Running the Code","metadata":{}},{"cell_type":"markdown","source":"## Define Hyper Parameters","metadata":{}},{"cell_type":"markdown","source":"#### files","metadata":{}},{"cell_type":"code","source":"# Raw\ntrain_data = {'en': 'data/train/train.en', 'fr': 'data/train/train.fr'}\nval_data = {'en': 'data/val/val.en', 'fr': 'data/val/val.fr'}\ntest_data = {'en': 'data/test/test_2017_flickr.en', 'fr': 'data/test/test_2017_flickr.fr'}\n\n# Preprocessed\nsource_train_file = 'data/train/train_tokenized_lowercased_bpe.fr'\ntarget_train_file = 'data/train/train_tokenized_lowercased_bpe.en'\nsource_val_file = 'data/val/val_tokenized_lowercased_bpe.fr'\ntarget_val_file = 'data/val/val_tokenized_lowercased_bpe.en'\nsource_test_file = 'data/test/test_2017_flickr_tokenized_lowercased_bpe.fr'\ntarget_test_file = 'data/test/test_2017_flickr_tokenized_lowercased_bpe.en'","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### Network Parameters","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-3\nmax_epochs = 30\nbatch_size = 256\n\nsource_vocab_size = 30000\ntarget_vocab_size = 30000\nhidden_dims = 128\nembedding_dims = 128\n\nsave_step = 100","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## process data","metadata":{}},{"cell_type":"markdown","source":"perform the preprocessing","metadata":{}},{"cell_type":"code","source":"preprocess(train_data, val_data, test_data, source_vocab_size)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/train/train.en > data/train/train_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/train/train_tokenized.en > data/train/train_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/train/train.fr > data/train/train_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/train/train_tokenized.fr > data/train/train_tokenized_lowercased.fr\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/val/val.en > data/val/val_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/val/val_tokenized.en > data/val/val_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/val/val.fr > data/val/val_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/val/val_tokenized.fr > data/val/val_tokenized_lowercased.fr\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/test/test_2017_flickr.en > data/test/test_2017_flickr_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/test/test_2017_flickr_tokenized.en > data/test/test_2017_flickr_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/test/test_2017_flickr.fr > data/test/test_2017_flickr_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/test/test_2017_flickr_tokenized.fr > data/test/test_2017_flickr_tokenized_lowercased.fr\n\nlearn vocab command:\tpython tools/subword-nmt/subword_nmt/learn_joint_bpe_and_vocab.py --input data/train/train_tokenized_lowercased.en data/train/train_tokenized_lowercased.fr -s 30000 -o data/codes.bpe --write-vocabulary data/vocab.en data/vocab.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/train/train_tokenized_lowercased.en > data/train/train_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/train/train_tokenized_lowercased.fr > data/train/train_tokenized_lowercased_bpe.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/val/val_tokenized_lowercased.en > data/val/val_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/val/val_tokenized_lowercased.fr > data/val/val_tokenized_lowercased_bpe.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/test/test_2017_flickr_tokenized_lowercased.en > data/test/test_2017_flickr_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/test/test_2017_flickr_tokenized_lowercased.fr > data/test/test_2017_flickr_tokenized_lowercased_bpe.fr\n","output_type":"stream"}]},{"cell_type":"markdown","source":"prepare data for the model","metadata":{}},{"cell_type":"code","source":"source_processor = DataProcessor(source_train_file, source_vocab_size)\ntarget_processor = DataProcessor(target_train_file, target_vocab_size)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## setup the Network","metadata":{}},{"cell_type":"code","source":"encdec = EncoderDecoder(embedding_dims, \n                        source_processor.vocab_size,\n                        source_processor.max_sentence_length,\n                        target_processor.vocab_size)\n\nif run_gpu:\n    encdec = encdec.cuda()\nopt = Adam(encdec.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"bla\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## training","metadata":{}},{"cell_type":"code","source":"####### Remove this\n# max_epochs = 5\n# batch_size = 4\n###########\n\nlosses = []\ncount = 0\ngen = batch_generator(source_processor, target_processor, batch_size)\nsentences_in_data = len(source_processor.sentences)\niterations = int(np.ceil(sentences_in_data/batch_size)*max_epochs)\n        \nfor it in tnrange(iterations): \n    output_i = it%save_step\n    out = 0\n    if output_i == 0:\n        if it != 0:\n            losses += output.tolist()\n            del(output)\n        if run_gpu:\n            output = torch.cuda.FloatTensor([0]*save_step)\n        else:\n            output = torch.FloatTensor([0]*save_step)\n    \n    opt.zero_grad()\n    \n    # Get the next bath of data and \n    words_batch_source, pos_batch_source, words_batch_target, sentence_lengths_source, sentence_lengths_target, source_mask, target_mask = next(gen)\n    \n    out = encdec(words_batch_source,\n                 pos_batch_source, \n                 sentence_lengths_source, \n                 words_batch_target, \n                 sentence_lengths_target, \n                 source_mask, \n                 target_mask)\n    \n    out.backward()\n    output[output_i] = out\n    opt.step()\n    count += batch_size\n    if count >= sentences_in_data:\n        count = 0\n        # Dump trained models\n        timestamp = datetime.now()\n        torch.save(encdec.state_dict(), 'model_it_{}_t_{:%m_%d_%H_%M}.torchsave'.format(it, timestamp))\nlosses += output.tolist()[:output_i+1]\ndel(output)\n\n# Dump trained models\ntimestamp = datetime.now()\ntorch.save(encdec.state_dict(), 'model_last-it_{}_t_{:%m_%d_%H_%M}.torchsave'.format(it, timestamp))","metadata":{"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=570), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2fbf66b29cb45d9b4460e6fcc11e23a"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('run_gpu:\\t\\t| '+str(run_gpu))\n# print('=====================================')\n# print('words_batch_source:\\t| ' +str(words_batch_source.is_cuda))\n# print('pos_batch_source:\\t| '   +str(pos_batch_source.is_cuda))\n# print('words_batch_target:\\t| ' +str(words_batch_target.is_cuda))\n# print('sen_len_source:\\t\\t| '   +str(sen_len_source.is_cuda))\n# print('all_embs:\\t\\t| '         +str(all_embs.is_cuda))\n# print('hidden_state_batch:\\t| ' +str(hidden_state_batch.is_cuda))\n# print('prediction:\\t\\t| '       +str(prediction.is_cuda))\n# print('output:\\t\\t\\t| '         +str(output.is_cuda))\n# print('out:\\t\\t\\t| '           +str(out.is_cuda))","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# losses2 = [item for sublist in losses for item in sublist]\n# losses","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Plot losses","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(20,15))\nplt.scatter(range(len(losses)),losses)\ny = losses[0:10]\nplt.show()","metadata":{"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x2149869a470>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## prediction","metadata":{}},{"cell_type":"markdown","source":"load trained models","metadata":{}},{"cell_type":"code","source":"# encoder = Encoder(source_processor.vocab_size,\n#                   source_processor.max_sentence_length+1, \n#                   embeddings_dim=embedding_dims)\n# decoder = Decoder(target_processor.vocab_size, \n#                   embeddings_dim=embedding_dims)\n\n# trained_encoder_file = 'encoder_it_144999_t_05_24_16_31'\n# trained_decoder_file = 'decoder_it_144999_t_05_24_16_31'\n# encoder.load_state_dict(torch.load(trained_encoder_file))\n# decoder.load_state_dict(torch.load(trained_decoder_file))\n\nencdec = EncoderDecoder(embedding_dims,\n                        source_processor.vocab_size,\n                        source_processor.max_sentence_length,\n                        target_processor.vocab_size)\n\ntrained_model_file = 'trained_model/initial_batched_run_30pseudo-epochs/encoder_last-it_13619_t_05_25_01_06.torchsave'\n\nsaved_state = torch.load(trained_model_file, map_location=lambda storage, loc: storage) # Bring from cuda\nencdec.load_state_dict(saved_state)\n\n# Use submodules for prediction\nencoder = encdec.encoder\ndecoder = encdec.decoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_id = trained_model_file[trained_model_file.rfind('/')+1:-3]\nprediction_file_name = 'test_{}.pred'.format(file_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_processor_test = DataProcessor(source_test_file, None)\ntarget_processor_test = DataProcessor(target_test_file, None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_sentences = []\nattention_weights = [] # list of (source_sentence, predicted_sentence, alphas) items\n\nfor s in source_processor_test.sentences:\n    mask = torch.from_numpy(np.ones([1,len(s)])).type(torch.FloatTensor)\n    words_tokens = torch.LongTensor([source_processor_test.w2i[w] for w in s])\n    pos_tokens = torch.LongTensor([i for i in range(len(s))])\n    \n    # Encode\n    all_embs, mean_emb = encoder(words_tokens.view(1, len(s)),\n                                 pos_tokens.view(1, len(s)), \n                                 torch.FloatTensor([len(s)]),\n                                 mask)\n    \n    # Decode\n    predicted_words = []\n    \n    start_token = torch.LongTensor([target_processor.w2i[START]])\n    prediction = start_token.view(1,1)\n    \n    hidden_state_batch = mean_emb\n    \n    for w_idx in range(target_processor.max_sentence_length):# loop until EOS is produced or a max is reached (max_sentence_length)\n        prediction, hidden_state_batch, alphas = decoder(\n            prediction, # the previous prediction\n            hidden_state_batch,\n            all_embs)\n        \n        index_predicted_word = np.argmax(prediction.detach().numpy(), axis=2)[0][0]\n        predicted_word = target_processor.i2w[index_predicted_word]\n        predicted_words.append(predicted_word)\n        \n        if predicted_word == END:\n            break\n            \n        prediction = torch.LongTensor([index_predicted_word]).view(1,1)\n    \n    predicted_sentences.append(predicted_words)\n    attention_weights.append((s, predicted_words, alphas.squeeze()[:w_idx].detach().numpy()))\n    \nwith open(prediction_file_name, 'w', encoding='utf-8') as f:\n    for p,_ in predicted_sentences:\n        if p[-1] == END:\n            p = p[:-1]\n        f.write(' '.join(p) + '\\n')\n\nprint('Predictions ready in file: {}'.format(prediction_file_name))\n\npickles.dump(attention_weights, file_id + '_prediction_weights')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### attention visualization","metadata":{}},{"cell_type":"code","source":"# attention_weights = []\n# attention_weights.append(('c \\' est la premiere ligne'.split(), 'this is the first sentence'.split(), np.random.random([6])))\n# attention_weights.append(('c \\' est la deuxieme ligne'.split(), 'this is the second sentence'.split(), np.random.random([6])))\n# attention_weights.append(('c \\' est la troisieme ligne'.split(), 'this is the third sentence'.split(), np.random.random([6])))\n# print(attention_weights)\n\ndef visualize_attention(source_sentence, target_sentence, weights):\n    weights = np.random.random((len(source_sentence), len(target_sentence)))\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(weights, cmap='bone')\n    fig.colorbar(cax)\n    \n    ax.set_yticklabels([''] + source_sentence)\n    ax.set_xticklabels([''] + target_sentence, rotation=45)\n    \n#     plt.show()\n    plt.savefig('{}_pred'.format(file_id))\n    \nsentence_id = 0\nitem = attention_weights[sentence_id]\nvisualize_attention(item[0], item[1], item[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"markdown","source":"Restore original segmentation","metadata":{}},{"cell_type":"code","source":"prediction_restored = prediction_file_name[:-5] + '_restored.pred'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sed -r 's/(@@ )|(@@ ?$)//g' Use the Powershell version instead. Watch for ASCII!\n\nrestore_command = 'get-content {input_file} | %{{$_ -replace \"(@@ )|(@@ ?$)\",\"\"}} | out-file {output_file} -encoding ASCII'.format(\n    input_file = prediction_file_name,\n    output_file = prediction_restored)\n\nprint('restore file command:\\t', restore_command)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BLEU","metadata":{}},{"cell_type":"code","source":"bleu_command = 'perl tools/mosesdecoder/scripts/generic/multi-bleu.perl -lc data/test/test_2017_flickr_tokenized_lowercased.en < {} > {}'.format(\n    prediction_restored,\n    'bleu_results/' + file_id + '.bleu')\n\nprint('bleu file command:\\t', bleu_command)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Meteor","metadata":{}},{"cell_type":"code","source":"meteor_command = 'java -jar tools/meteor-1.5/meteor-1.5.jar {} data/test/test_2017_flickr_tokenized_lowercased.en > {}'.format(\n    prediction_restored,\n    'meteor_results/' + file_id + '.meteor')\n\nprint('meteor command:\\t', meteor_command)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TER","metadata":{}},{"cell_type":"code","source":"# Append ids to both gold and prediction files\ngold = 'data/test/test_2017_flickr_tokenized_lowercased.en'\ngold_ter = gold[:-3] + '_ter.en'\n\nprediction_restored_ter = prediction_restored[:-5] + '_ter.pred'\n\nwith open(gold, 'r') as fi, open(gold_ter, 'w') as fo:\n    for i, line in enumerate(fi.readlines()):\n        last_char = line[-1]\n        fo.write('{} ({}){}'.format(line[:-1], i, last_char))\n\nwith open(prediction_restored, 'r') as fi, open(prediction_restored_ter, 'w') as fo:\n    for i, line in enumerate(fi.readlines()):\n        last_char = line[-1]\n        fo.write('{} ({}){}'.format(line[:-1], i, last_char))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ter_command = 'java -jar tools/tercom-0.7.25/tercom.7.25.jar -r {} -h {} -n {} > {}'.format(\n    gold_ter,\n    prediction_restored_ter,\n    'ter_results/' + file_id,\n    'ter_results/' + file_id + '_out.txt')\n\nprint('ter command:\\t', ter_command)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### beam search","metadata":{}},{"cell_type":"code","source":"class Hypothesis(object):\n    \"\"\"use for decoding\"\"\"\n    def __init__(self, perm, score, state):\n        self.perm = perm\n        self.score = score\n        self.state = state\n\n    def update(self):\n        return\n\ndef decode(sent, beam_size):\n    \"\"\"Beam search decoder\"\"\"\n    \"\"\"bin: keep track of hypothesis, bin[i] contains all the hypotheses of length i\"\"\"\n    bin = [] # to keep track of hypothesis\n\n    # first of all, we need to encode the whole source sentence\n    # since this is done only one time\n    # map word to its id\n    fids = map(numberizer.numberize, sent[:-1])\n    enc_state = encode(fids)\n    \"\"\"\n        enc_state is a computational graph\n        it's very expensive to use it during decoding, since the graph will be recomputed each time\n        and during decoding, we don't update parameter, so we would like to fix enc_state\n        This is done nicely by compute the actual value of enc_state\n    \"\"\"\n    enc_state = constant(compute_value(enc_state))  # now it's a constant, accessing time is constant\n\n    \"\"\" the output layer also can be precomputed \"\"\"\n    out_layer = encode_birnn(fids)\n    out_layer = constant(compute_value(out_layer))  ## turn it to a precomputed big matrix\n    \"\"\" now we start the decoder with encoder state \"\"\"\n    dec.start(enc_state)\n    state0 = dec.step(embeddings[numberizer.numberize(\"<s>\")])\n    state0_const = constant(compute_value(state0))\n    # create the first hypothesis\n    h0 = Hypothesis([-1], 0.0, state0_const)\n    # put h0 to bin\n    stacks = []\n    stacks.append(h0)\n    bin.append(stacks)  # note that we put h0 in to a stack first\n\n    # now we can loop through number of source words\n    n = len(fids)\n    for i in range(n):\n        prev_stack = bin[i]\n        curr_stack = []\n        for hypo in prev_stack:\n            # expand it\n            # first, reset the decoder state\n            dec.start(hypo.state)\n            # update decoder state with the previous generated word\n            last_id = hypo.perm[-1]  # here it's just the position\n            # we get the actual word\n            word_id = fids[last_id]\n            # then turn it to a vector\n            last_inpt = embeddings[word_id]\n            # now, update decode\n            new_state = dec.step(last_inpt)\n            #compute the log output\n            log_prob = logsoftmax(dot(out_layer, new_state))\n            # actually compute it\n            log_prob = compute_value(log_prob)\n            # get out top beam_size log prob\n            \"\"\"Add your code here\"\"\"\n            for j,prob in enumerate(log_prob):\n                perm = list(hypo.perm)\n                #if not covered yet, extend the permutation\n                if(j not in perm):\n                    perm.append(j)\n                    new_prob = hypo.score + prob\n                    new_h = Hypothesis(perm,new_prob,new_state)\n                    curr_stack.append(new_h)\n\n        #if there more then 100 permutations, take the top 100\n        if len(curr_stack) > beam_size:\n            ordered_scores = []\n            #get the scores from the hypothesis\n            for h in curr_stack:\n                ordered_scores.append(h.score)\n            #get the indexs from 100 highest scores\n            locations = sorted(range(len(ordered_scores)), key=lambda i: ordered_scores[i])[-beam_size:]\n            #put top 100 in the bin\n            stacks = [curr_stack[i] for i in locations]\n            bin.append(stacks)\n        else:\n            bin.append(curr_stack)\n\n    ordered_scores = []\n    last_stack = bin[-1]\n    #get the scores from the hypothesis\n    for h in last_stack:\n        ordered_scores.append(h.score)\n\n    #return the hypothesis with highest score\n    return last_stack[ordered_scores.index(max(ordered_scores))].perm[1:]","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.5","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":2,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project 2","metadata":{}},{"cell_type":"markdown","source":"##### import needed packages","metadata":{}},{"cell_type":"code","source":"# from tqdm import tqdm_notebook, tqdm\nfrom collections import defaultdict,Counter\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom random import shuffle\nimport matplotlib.pyplot as plt\nnp.set_printoptions(threshold=np.nan)","metadata":{"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"# Classes and Functions","metadata":{}},{"cell_type":"markdown","source":"## Data Manipulation","metadata":{}},{"cell_type":"markdown","source":"### Cleaning and preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess(train_data, val_data, test_data, vocab_size=10000):\n    \n    # loop over all the given files\n    for data in [train_data, val_data, test_data]:\n        # contains a source and a target file\n        for k,v in data.items():\n            tokenized_path = v[:v.find('.')] + '_tokenized.{}'.format(k)\n\n            # Tokenize \n            tokenize_command = 'perl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l {lang} < {file_path} > {output_path}'.format(\n                lang=k, file_path=v, output_path=tokenized_path)\n            print('tokenize command:\\t{}'.format(tokenize_command))\n            \n            # Lowercase\n            lowercase_path = tokenized_path[:tokenized_path.find('.')] + '_lowercased.{}'.format(k)\n            lowercase_command = 'perl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < {file_path} > {output_path}'.format(\n                file_path=tokenized_path, output_path=lowercase_path)\n            print('lowercase command:\\t{}\\n'.format(lowercase_command))\n            \n    # BPE\n    # Get vocabulary using train data\n    script_name = 'python tools/subword-nmt/subword_nmt/learn_joint_bpe_and_vocab.py'\n    args = ' --input {train_en} {train_fr} -s {num_symbols} -o {codes_file} --write-vocabulary {vocab_file}.en {vocab_file}.fr'\n    substr_index = train_data['en'].find('/')\n    vocab_file_name = train_data['en'][:substr_index] + '/vocab'\n    codes_file_name = train_data['en'][:substr_index] + '/codes.bpe'\n    learn_vocab_command = script_name + args.format(\n        train_en='data/train/train_tokenized_lowercased.en',\n        train_fr='data/train/train_tokenized_lowercased.fr',\n        num_symbols=str(vocab_size),\n        codes_file=codes_file_name,\n        vocab_file=vocab_file_name\n    )\n    print('learn vocab command:\\t{}'.format(learn_vocab_command))\n    \n    # Process all files the same way for consistency\n    script_name = 'python tools/subword-nmt/subword_nmt/apply_bpe.py'\n    for data in [train_data, val_data, test_data]:\n        for k,v in data.items():\n            args = ' -c {codes_file} --vocabulary {vocab_file}.{lang} --vocabulary-threshold 50 < {train_file}.{lang} > {train_file}_bpe.{lang}'\n            train_file_name = v[:v.find('.')] + '_tokenized_lowercased'\n            bpe_command = script_name + args.format(\n                codes_file=codes_file_name,\n                vocab_file=vocab_file_name,\n                lang=k,\n                train_file=train_file_name\n            )\n            print('bpe command:\\t{}'.format(bpe_command))","metadata":{"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":"### Building dictionaries and vocabularies","metadata":{}},{"cell_type":"code","source":"UNK = '<UNK>'\nSTART = '<SOS>'\nEND = '<EOS>'\nPAD = '<PAD>'","metadata":{"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"class DataProcessor():\n    def __init__(self, file_name, vocab_size):\n        self.max_sentence_length = -1\n        self.vocab_size = vocab_size\n        \n        self.file_name = file_name\n        self.sentences = self.load_data()\n        self.vocab,self.vocab_size = self.build_vocab()\n        self.w2i, self.i2w = self.build_dicts()        \n        \n    def load_data(self):\n        sentences = []\n        with open(self.file_name, 'r') as f:\n            for raw_line in f:\n                line = '{s} {l} {e}'.format(s=START, l=raw_line, e=END)\n                sentences.append(line.split())                \n        return sentences\n    \n    def build_dicts(self):\n        \"\"\"\n        creates lookup tables to find the index given the word \n        and the otherway around \n        \"\"\"\n        w2i = defaultdict(lambda: w2i[UNK])# would something like this work? not entirely, needs some tweaking\n        i2w = dict()\n        for i,w in enumerate(self.vocab):\n            i2w[i] = w\n            w2i[w] = i\n        return w2i, i2w    \n    \n    def build_vocab(self): \n        \"\"\"\n        builds a vocabulary with the most occuring words, in addition to\n        the UNK token at index 0.\n        START and END tokens are added to the vocabulary through the\n        preprocessed sentences.\n        with vocab size none, all existing words in the data are used\n        \"\"\"\n        vocab = Counter()\n        for s in self.sentences:\n            l = len(s)\n            if l > self.max_sentence_length:\n                self.max_sentence_length = l\n            for w in s:\n                vocab[w] += 1\n\n        vocab = [k for k,_ in vocab.most_common(self.vocab_size)]\n        vocab = [UNK, PAD] + vocab\n        return vocab,len(vocab)","metadata":{"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"markdown","source":"### Getting data batches","metadata":{}},{"cell_type":"code","source":"def batch_generator(source_processor, target_processor, batch_size):\n    idx = np.arange(len(source_processor.sentences))\n    \n    while True:\n        shuffle(idx)\n        batch_idx = [idx[i:i + batch_size] for i in range(0, len(idx) - (len(idx)%batch_size), batch_size)]\n        \n        for b_idx in batch_idx:\n            b_words_source = np.zeros([batch_size, source_processor.max_sentence_length])\n            b_positions_source = np.zeros([batch_size, source_processor.max_sentence_length])\n            b_words_target = np.zeros([batch_size, target_processor.max_sentence_length])\n            \n            sentence_lengths_source = []\n            sentence_lengths_target = []\n            \n            for i, bi in enumerate(b_idx):\n                sent_source = source_processor.sentences[bi]\n                sent_target = target_processor.sentences[bi]\n                \n                b_words_source[i, :len(sent_source)] = np.array([source_processor.w2i[w] for w in sent_source])\n                b_positions_source[i, :len(sent_source)] = np.array([i for i in range(len(sent_source))])\n                b_words_target[i, :len(sent_target)] = np.array([target_processor.w2i[w] for w in sent_target])\n                \n                sentence_lengths_source.append(len(sent_source))\n                sentence_lengths_target.append(len(sent_target))\n            \n            yield (torch.from_numpy(b_words_source).type(torch.LongTensor),\n                   torch.from_numpy(b_positions_source).type(torch.LongTensor),\n                   torch.from_numpy(b_words_target).type(torch.LongTensor),\n                   sentence_lengths_source,\n                   sentence_lengths_target)","metadata":{"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":"## Sequence 2 Sequence RNN's","metadata":{}},{"cell_type":"markdown","source":"### Encoders","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, source_vocab_size, source_max_length, embeddings_dim):\n        super().__init__()        \n        self.word_embeddings = nn.Embedding(source_vocab_size, embeddings_dim)\n        self.pos_embeddings = nn.Embedding(source_max_length, embeddings_dim)\n        \n    def forward(self, words_batch, pos_batch, sentence_lengths): # all inputs are tensors\n        words_emb = self.word_embeddings(words_batch)\n        pos_emb = self.pos_embeddings(pos_batch)\n        full_emb = torch.add(words_emb,pos_emb)\n        mean_emb = full_emb.sum(dim=1).float().div(sentence_lengths.view(-1,1)) # batched version of torch.mean(full_emb,1)\n                                           \n        return full_emb, mean_emb","metadata":{"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"markdown","source":"### Decoders","metadata":{}},{"cell_type":"code","source":"# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n\nclass Decoder(nn.Module):\n    def __init__(self, target_vocab_size, embeddings_dim, max_output_sentence_length, dropout_p=0.1): # embeddings is hidden, vocab size is output size\n        super().__init__()\n        \n        self.embedding_dim = embedding_dims\n        self.dropout_p = dropout_p\n#         self.max_length = max_output_sentence_length\n        \n        self.target_embeddings = nn.Embedding(target_vocab_size, embeddings_dim)\n        self.gru = nn.GRU(embeddings_dim*2, embeddings_dim, batch_first=True) # gru is an LSTM, and has 2 outputs\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.out = nn.Linear(embeddings_dim, target_vocab_size)\n        \n    def forward(self, gold_words_batch, hidden_batch, stacked_encoded_words_batch):        \n        batch_size = gold_words_batch.size(0)\n        encoded_length = stacked_encoded_words_batch.size(1)\n        \n        emb = self.target_embeddings(gold_words_batch)\n        emb = self.dropout(emb)\n        \n        # attention        \n        alphas = torch.zeros(batch_size, encoded_length)\n        alphas = hidden_batch.view(batch_size,1,self.embedding_dim).bmm(\n            stacked_encoded_words_batch.view(batch_size,self.embedding_dim,encoded_length))\n        \n        # Turn to probability distribution\n        alphas = F.softmax(alphas, dim=2)\n                \n        # context is weights x hidden states from encoder\n        context = torch.bmm(alphas, stacked_encoded_words_batch)     \n        \n        # we have to concat context + emb        \n        input = torch.cat((emb, context), 2)\n        \n        gru_output, hidden = self.gru(input, hidden_batch.view(1, batch_size, self.embedding_dim))\n        \n        output = self.out(gru_output)\n        output = F.log_softmax(output, dim=1)\n        \n        return output, hidden","metadata":{"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"markdown","source":"# Running the Code","metadata":{}},{"cell_type":"markdown","source":"## Define Hyper Parameters","metadata":{}},{"cell_type":"markdown","source":"#### files","metadata":{}},{"cell_type":"code","source":"# Raw\ntrain_data = {'en': 'data/train/train.en', 'fr': 'data/train/train.fr'}\nval_data = {'en': 'data/val/val.en', 'fr': 'data/val/val.fr'}\ntest_data = {'en': 'data/test/test_2017_flickr.en', 'fr': 'data/test/test_2017_flickr.fr'}\n\n# Preprocessed\nsource_train_file = 'data/train/train_tokenized_lowercased_bpe.fr'\ntarget_train_file = 'data/train/train_tokenized_lowercased_bpe.en'\nsource_val_file = 'data/val/val_tokenized_lowercased_bpe.fr'\ntarget_val_file = 'data/val/val_tokenized_lowercased_bpe.en'\nsource_test_file = 'data/test/test_2017_flickr_tokenized_lowercased_bpe.fr'\ntarget_test_file = 'data/test/test_2017_flickr_tokenized_lowercased_bpe.en'","metadata":{"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":"#### Network Parameters","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-3\niterations = 1\nbatch_size = 16\n\nsource_vocab_size = 30000\ntarget_vocab_size = 30000\nhidden_dims = 128\nembedding_dims = 128","metadata":{"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":"## process data","metadata":{}},{"cell_type":"markdown","source":"perform the preprocessing","metadata":{}},{"cell_type":"code","source":"preprocess(train_data, val_data, test_data, source_vocab_size)","metadata":{},"execution_count":353,"outputs":[{"text":"tokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/train/train.en > data/train/train_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/train/train_tokenized.en > data/train/train_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/train/train.fr > data/train/train_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/train/train_tokenized.fr > data/train/train_tokenized_lowercased.fr\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/val/val.en > data/val/val_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/val/val_tokenized.en > data/val/val_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/val/val.fr > data/val/val_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/val/val_tokenized.fr > data/val/val_tokenized_lowercased.fr\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en < data/test/test_2017_flickr.en > data/test/test_2017_flickr_tokenized.en\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/test/test_2017_flickr_tokenized.en > data/test/test_2017_flickr_tokenized_lowercased.en\n\ntokenize command:\tperl tools/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fr < data/test/test_2017_flickr.fr > data/test/test_2017_flickr_tokenized.fr\nlowercase command:\tperl tools/mosesdecoder/scripts/tokenizer/lowercase.perl < data/test/test_2017_flickr_tokenized.fr > data/test/test_2017_flickr_tokenized_lowercased.fr\n\nlearn vocab command:\tpython tools/subword-nmt/subword_nmt/learn_joint_bpe_and_vocab.py --input data/train/train_tokenized_lowercased.en data/train/train_tokenized_lowercased.fr -s 30000 -o data/codes.bpe --write-vocabulary data/vocab.en data/vocab.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/train/train_tokenized_lowercased.en > data/train/train_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/train/train_tokenized_lowercased.fr > data/train/train_tokenized_lowercased_bpe.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/val/val_tokenized_lowercased.en > data/val/val_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/val/val_tokenized_lowercased.fr > data/val/val_tokenized_lowercased_bpe.fr\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.en --vocabulary-threshold 50 < data/test/test_2017_flickr_tokenized_lowercased.en > data/test/test_2017_flickr_tokenized_lowercased_bpe.en\nbpe command:\tpython tools/subword-nmt/subword_nmt/apply_bpe.py -c data/codes.bpe --vocabulary data/vocab.fr --vocabulary-threshold 50 < data/test/test_2017_flickr_tokenized_lowercased.fr > data/test/test_2017_flickr_tokenized_lowercased_bpe.fr\n","name":"stdout","output_type":"stream"}]},{"cell_type":"markdown","source":"prepare data for the model","metadata":{}},{"cell_type":"code","source":"source_processor = DataProcessor(source_train_file, source_vocab_size)\ntarget_processor = DataProcessor(target_train_file, target_vocab_size)","metadata":{"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":"## setup the Network","metadata":{}},{"cell_type":"code","source":"encoder = Encoder(source_processor.vocab_size,\n                  source_processor.max_sentence_length, \n                  embeddings_dim=embedding_dims)\ndecoder = Decoder(target_processor.vocab_size, \n                  embeddings_dim=embedding_dims, \n                  max_output_sentence_length=target_processor.max_sentence_length)\n\nopt_encoder = Adam(encoder.parameters(), lr=learning_rate)\nopt_decoder = Adam(decoder.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"markdown","source":"## training","metadata":{}},{"cell_type":"code","source":"gen = batch_generator(source_processor, target_processor, batch_size)\nlosses = []\n\nfor it in range(iterations):    \n    output = 0\n    loss = nn.NLLLoss(ignore_index=target_processor.w2i[PAD])\n    \n    opt_encoder.zero_grad()\n    opt_decoder.zero_grad()\n\n    words_batch_source, pos_batch_source, words_batch_target, sentence_lengths_source, sentence_lengths_target = next(gen)\n    \n    # Encode\n    all_embs, mean_emb = encoder(words_batch_source, pos_batch_source, torch.FloatTensor(sentence_lengths_source))\n\n    # Decode\n    hidden_state_batch = mean_emb\n    \n#     for w_idx in range(target_processor.max_sentence_length):\n    for w_idx in range(max(sentence_lengths_target)):\n        prediction, hidden_state_batch = decoder(\n            words_batch_target[:,w_idx].view(-1,1), \n            hidden_state_batch,\n            all_embs)\n        \n        output += loss(prediction.view(batch_size, target_processor.vocab_size), \n                       words_batch_target[:,w_idx])\n    \n    losses.append(output) # the loss is the average of losses, so divide over number of words in each sentence\n    \n    output.backward()\n\n    opt_encoder.step()\n    opt_decoder.step()\n    \n    \n# TODO: Should we run until convergence on validation set? probably, if there is time","metadata":{"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"markdown","source":"Plot losses","metadata":{}},{"cell_type":"code","source":"plt.plot(losses)\nplt.show()\nlosses","metadata":{},"execution_count":358,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{}},{"execution_count":358,"output_type":"execute_result","data":{"text/plain":"[tensor(0.)]"},"metadata":{}}]},{"cell_type":"markdown","source":"## prediction","metadata":{}},{"cell_type":"code","source":"source_processor_test = DataProcessor(source_test_file, source_vocab_size) # TODO: This has to use all vocab\ntarget_processor_test = DataProcessor(target_test_file, target_vocab_size) # TODO: This has to use all vocab","metadata":{"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"predicted_sentences = []\n\nfor s in source_processor_test.sentences:\n    words_tokens = torch.LongTensor([source_processor_test.w2i[w] for w in s])\n    pos_tokens = torch.LongTensor([i for i in range(len(s))])\n    \n    # Encode\n    all_embs, mean_emb = encoder(words_tokens.view(1, len(s)),\n                                 pos_tokens.view(1, len(s)), \n                                 torch.FloatTensor([len(s)]))\n    \n    # Decode\n    predicted_words = []\n    \n    start_token = torch.LongTensor([target_processor.w2i[START]])\n    prediction = start_token.view(1,1)\n    \n    hidden_state_batch = mean_emb\n    \n    for w_idx in range(target_processor.max_sentence_length):# loop until EOS is produced or a max is reached (max_sentence_length)\n        prediction, hidden_state_batch = decoder(\n            prediction, # the previous prediction\n            hidden_state_batch,\n            all_embs)\n        \n        index_predicted_word = np.argmax(prediction.detach().numpy(), axis=2)[0][0]\n        predicted_word = target_processor.i2w[index_predicted_word]\n        predicted_words.append(predicted_word)\n        \n        if predicted_word == END:\n            break\n            \n        prediction = torch.LongTensor([index_predicted_word]).view(1,1)\n    \n    predicted_sentences.append(predicted_words)\n    \n    break  ### TODO: Remove this to predict on the whole test set #################\n    \nprint(predicted_sentences)","metadata":{"trusted":true},"execution_count":225,"outputs":[{"name":"stdout","text":"[['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# Don't forget to do:\n# sed -r 's/(@@ )|(@@ ?$)//g' ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BLEU","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Meteor","metadata":{}},{"cell_type":"markdown","source":"### TER","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}